{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec31851a-3b4e-4db0-bdad-e2be13979bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jozsa\\AppData\\Local\\Temp\\ipykernel_1556\\109909311.py:21: DeprecationWarning: Accessing jax.config via the jax.config submodule is deprecated.\n",
      "  from jax.config import config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax backend cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, json\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "import optax\n",
    "from functools import partial\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "import numpy\n",
    "from pdb import set_trace\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import jax\n",
    "from jax import random \n",
    "from jax.config import config\n",
    "import jax.numpy as np\n",
    "from jax import vmap\n",
    "from jax.lib import xla_bridge\n",
    "\n",
    "print(\"jax backend {}\".format(xla_bridge.get_backend().platform))\n",
    "\n",
    "from SSN_classes import SSN2DTopoV1_ONOFF_local, SSN2DTopoV1\n",
    "from util import take_log, load_param_from_csv\n",
    "from analysis import param_ratios_two_layer\n",
    "from visualization import (\n",
    "    plot_losses,\n",
    "    plot_losses_two_stage,\n",
    "    plot_results_two_layers,\n",
    "    plot_sigmoid_outputs,\n",
    "    plot_training_accs,\n",
    ")\n",
    "from training import *\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a95dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".XX\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb98a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate find A and save\n",
    "# BW_Grating(JiaGrating) is called 81 times and spatial_frequency is always 0.05235987755982988\n",
    "ssn_mid = SSN2DTopoV1_ONOFF_local(\n",
    "    ssn_pars=ssn_pars, # got c_E and c_I as new parameters\n",
    "    grid_pars=grid_pars,\n",
    "    conn_pars=conn_pars_m,\n",
    "    filter_pars=filter_pars,\n",
    "    J_2x2 = ssn_layer_pars.J_2x2_m,\n",
    "    gE = ssn_layer_pars.gE_m, \n",
    "    gI = ssn_layer_pars.gE_s\n",
    ")\n",
    "\n",
    "ssn_pars.A = ssn_mid.A\n",
    "if ssn_pars.phases == 4:\n",
    "    ssn_pars.A2 = ssn_mid.A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db1056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load orientation map, MJ\n",
    "# ssn_ori_map = np.load(os.path.join(os.getcwd(), \"ssn_map_uniform_good.npy\"))\n",
    "\n",
    "####################### TRAINING PARAMETERS #############################\n",
    "epochs_to_save = np.insert(\n",
    "    (np.unique(np.linspace(1, training_pars.epochs, training_pars.num_epochs_to_save).astype(int))), 0, 0\n",
    ")\n",
    "\n",
    "constant_ssn_pars = dict(\n",
    "    ssn_pars=ssn_pars,\n",
    "    grid_pars=grid_pars,\n",
    "    conn_pars_m=conn_pars_m,\n",
    "    conn_pars_s=conn_pars_s,\n",
    "    gE=ssn_layer_pars.gE,\n",
    "    gI=ssn_layer_pars.gI,\n",
    "    filter_pars=filter_pars,\n",
    "    conv_pars=conv_pars,# this got a lot of new stuff in it that might be a problem\n",
    "    loss_pars=loss_pars,\n",
    "    noise_type=\"poisson\",\n",
    ")\n",
    "\n",
    "\n",
    "##################### SAVE RESULTS ###############################\n",
    "\n",
    "# Name of results csv\n",
    "home_dir = os.getcwd()\n",
    "\n",
    "# Specify folder to save results\n",
    "results_dir = os.path.join(\n",
    "    home_dir,\n",
    "    \"results\",\n",
    "    \"16-10\",\n",
    "    \"phases_\"\n",
    "    + str(ssn_pars.phases)\n",
    "    + \"k_\"\n",
    "    + str(filter_pars.k)\n",
    "    + \"sigma_g\"\n",
    "    + str(filter_pars.sigma_g)\n",
    "    + \"gE_\"\n",
    "    + str(ssn_layer_pars.gE_m),\n",
    ")\n",
    "\n",
    "if os.path.exists(results_dir) == False:\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# Specify results filename\n",
    "run_dir = os.path.join(\n",
    "    results_dir,\n",
    "    \"set_\"\n",
    "    + str(\"C\") # init_set_m = \"C\" but I removed it for now\n",
    "    + \"_sig_noise_\"\n",
    "    + str(training_pars.sig_noise)\n",
    "    + \"_batch\"\n",
    "    + str(training_pars.batch_size)\n",
    "    + \"_lamw\"\n",
    "    + str(loss_pars.lambda_w),\n",
    ")\n",
    "\n",
    "# results_filename = None\n",
    "results_filename = os.path.join(run_dir + \"_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5b134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new orientation map\n",
      "[[172.69487   178.23965   133.35286   103.09104   153.8738    141.5435\n",
      "  176.7622    124.5456    105.62035  ]\n",
      " [ 35.97815    71.58959    91.989395   69.425575   71.99754   137.70273\n",
      "  165.12189   117.94913    25.136189 ]\n",
      " [ 67.84493   162.46297   142.57837     9.007031    5.950877   60.928127\n",
      "   90.58961   162.18724    19.068493 ]\n",
      " [ 27.085865  172.8008    160.01271   165.47255    27.742746   50.21197\n",
      "  143.7793    123.68952   149.20287  ]\n",
      " [ 54.598164  139.32262   121.20855   130.1541    143.99326   135.25891\n",
      "  149.17587   157.32765   174.68413  ]\n",
      " [  4.6704493  19.878267  113.98101   134.3164     74.109085    8.544313\n",
      "  157.88673    76.33787   120.63373  ]\n",
      " [176.80812    29.161428   87.669754   79.10616    64.27215   155.54132\n",
      "  168.56268    41.841663   55.3378   ]\n",
      " [ 16.996605  162.2735    167.24075   160.00632    21.834236  138.0646\n",
      "  142.49863    14.115802  175.33542  ]\n",
      " [ 63.618965  155.439     162.59659    16.884869    5.497428   54.782425\n",
      "  111.31825   159.88333   129.41362  ]]\n",
      "Training model for 3 epochs  with learning rate 0.001, sig_noise 2.0 at offset 4.0, lam_w 1, batch size 50, noise_type poisson\n",
      "Loss parameters dx 1, w 1 \n",
      "Saving results to csv  C:\\Users\\jozsa\\Desktop\\Postdoc 2023-24\\ABL-MJ\\results\\16-10\\phases_2k_1.0471975511965976sigma_g0.1875gE_0.3\\set_C_sig_noise_2.0_batch50_lamw1_results.csv\n",
      "MJ check for r_ref Traced<ShapedArray(float32[25])>with<DynamicJaxprTrace(level=4/0)>\n",
      "Traced<ShapedArray(float32[25])>with<DynamicJaxprTrace(level=4/0)>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mul got incompatible shapes for broadcasting: (250,), (25,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m########### TRAINING ############\u001b[39;00m\n\u001b[0;32m      2\u001b[0m (\n\u001b[0;32m      3\u001b[0m     [ssn_layer_pars, readout_pars],\n\u001b[0;32m      4\u001b[0m     val_loss_per_epoch,\n\u001b[0;32m      5\u001b[0m     training_losses,\n\u001b[0;32m      6\u001b[0m     training_accs,\n\u001b[0;32m      7\u001b[0m     train_sig_inputs,\n\u001b[0;32m      8\u001b[0m     train_sig_outputs,\n\u001b[0;32m      9\u001b[0m     val_sig_inputs,\n\u001b[0;32m     10\u001b[0m     val_sig_outputs,\n\u001b[0;32m     11\u001b[0m     epoch_c,\n\u001b[0;32m     12\u001b[0m     save_w_sigs,\n\u001b[1;32m---> 13\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mnew_two_stage_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssn_layer_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msig_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstant_ssn_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstimuli_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ssn_ori_map=ssn_ori_map,\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_pars \u001b[39m\u001b[38;5;124m\"\u001b[39m, ssn_layer_pars, readout_pars)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save training and validation losses\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Postdoc 2023-24\\ABL-MJ\\training.py:162\u001b[0m, in \u001b[0;36mnew_two_stage_training\u001b[1;34m(ssn_layer_pars, sigm_pars, training_pars, constant_ssn_pars, stimuli_pars, results_filename, second_eta, test_size, results_dir, early_stop, extra_stop, ssn_ori_map)\u001b[0m\n\u001b[0;32m    151\u001b[0m constant_ssn_pars \u001b[38;5;241m=\u001b[39m generate_noise(\n\u001b[0;32m    152\u001b[0m     constant_ssn_pars,\n\u001b[0;32m    153\u001b[0m     sig_noise\u001b[38;5;241m=\u001b[39msig_noise,\n\u001b[0;32m    154\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    155\u001b[0m     length\u001b[38;5;241m=\u001b[39mw_sig\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[0;32m    159\u001b[0m [\n\u001b[0;32m    160\u001b[0m     epoch_loss,\n\u001b[0;32m    161\u001b[0m     [epoch_all_losses, train_true_acc, train_delta_x, train_x, train_r_ref],\n\u001b[1;32m--> 162\u001b[0m ], grad \u001b[38;5;241m=\u001b[39m \u001b[43mloss_and_grad_readout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssn_layer_pars_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadout_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_ssn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_flag\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m training_losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\Desktop\\Postdoc 2023-24\\ABL-MJ\\training_supp.py:484\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(ssn_layer_pars, readout_pars, constant_ssn_pars, data, debug_flag)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(ssn_layer_pars, readout_pars, constant_ssn_pars, data, debug_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    476\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03m    Function to take gradient with respect to. Output returned as two variables (jax grad takes gradient with respect to first output)\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m    Inputs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m        total loss to take gradient with respect to\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     total_loss, all_losses, pred_label, sig_input, x, max_rates \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssn_layer_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssn_layer_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreadout_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreadout_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstant_ssn_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstant_ssn_pars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_flag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m     loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(total_loss)\n\u001b[0;32m    492\u001b[0m     all_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(all_losses, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Postdoc 2023-24\\ABL-MJ\\training_supp.py:472\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(ssn_layer_pars, readout_pars, constant_ssn_pars, data, debug_flag)\u001b[0m\n\u001b[0;32m    469\u001b[0m noise_type \u001b[38;5;241m=\u001b[39m constant_ssn_pars[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    470\u001b[0m train_ori \u001b[38;5;241m=\u001b[39m constant_ssn_pars[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_ori\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_model_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogJ_2x2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs_2x2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_E\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_I\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_E\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_I\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_sig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_sig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_oris\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssn_mid_ori_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssn_mid_ori_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_pars_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_pars_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgE_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgI_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgE_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgI_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_flag\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\Desktop\\Postdoc 2023-24\\ABL-MJ\\training_supp.py:390\u001b[0m, in \u001b[0;36m_new_model\u001b[1;34m(logJ_2x2, logs_2x2, c_E, c_I, f_E, f_I, w_sig, b_sig, sigma_oris, kappa_pre, kappa_post, ssn_mid_ori_map, ssn_sup_ori_map, train_data, ssn_pars, grid_pars, conn_pars_m, conn_pars_s, gE_m, gI_m, gE_s, gI_s, filter_pars, conv_pars, loss_pars, noise_ref, noise_target, noise_type, train_ori, debug_flag)\u001b[0m\n\u001b[0;32m    387\u001b[0m     r_target \u001b[38;5;241m=\u001b[39m r_target\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m noise_target)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m noise_type \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 390\u001b[0m     r_ref \u001b[38;5;241m=\u001b[39m r_ref \u001b[38;5;241m+\u001b[39m \u001b[43mnoise_ref\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_ref\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m     r_target \u001b[38;5;241m=\u001b[39m r_target \u001b[38;5;241m+\u001b[39m noise_target\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftplus(r_target))\n\u001b[0;32m    393\u001b[0m delta_x \u001b[38;5;241m=\u001b[39m r_ref \u001b[38;5;241m-\u001b[39m r_target\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\SSN_env\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:728\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 728\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\SSN_env\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:256\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    254\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\SSN_env\\lib\\site-packages\\jax\\_src\\numpy\\ufuncs.py:97\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2, \u001b[38;5;241m/\u001b[39m):\n\u001b[0;32m     96\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m promote_args(numpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, x1, x2)\n\u001b[1;32m---> 97\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[1;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\SSN_env\\lib\\site-packages\\jax\\_src\\lax\\lax.py:1591\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[1;34m(name, *avals)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1592\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[1;31mTypeError\u001b[0m: mul got incompatible shapes for broadcasting: (250,), (25,)."
     ]
    }
   ],
   "source": [
    "########### TRAINING ############\n",
    "(\n",
    "    [ssn_layer_pars, readout_pars],\n",
    "    val_loss_per_epoch,\n",
    "    training_losses,\n",
    "    training_accs,\n",
    "    train_sig_inputs,\n",
    "    train_sig_outputs,\n",
    "    val_sig_inputs,\n",
    "    val_sig_outputs,\n",
    "    epoch_c,\n",
    "    save_w_sigs,\n",
    ") = new_two_stage_training(\n",
    "    ssn_layer_pars,\n",
    "    sig_pars,\n",
    "    training_pars,\n",
    "    constant_ssn_pars,\n",
    "    stimuli_pars,\n",
    "    results_filename=results_filename,\n",
    "    results_dir=run_dir,\n",
    "    extra_stop=2,\n",
    "    # ssn_ori_map=ssn_ori_map,\n",
    ")\n",
    "\n",
    "print(\"new_pars \", ssn_layer_pars, readout_pars)\n",
    "\n",
    "# Save training and validation losses\n",
    "np.save(os.path.join(run_dir + \"_training_losses.npy\"), training_losses)\n",
    "np.save(os.path.join(run_dir + \"_validation_losses.npy\"), val_loss_per_epoch)\n",
    "\n",
    "# Plot losses\n",
    "losses_dir = os.path.join(run_dir + \"_losses\")\n",
    "plot_losses_two_stage(\n",
    "    training_losses, val_loss_per_epoch, epoch_c=epoch_c, save=losses_dir, inset=False\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "results_plot_dir = os.path.join(run_dir + \"_results\")\n",
    "plot_results_two_layers(\n",
    "    results_filename, bernoulli=False, epoch_c=epoch_c, save=results_plot_dir\n",
    ")\n",
    "\n",
    "# Plot sigmoid\n",
    "sig_dir = os.path.join(run_dir + \"_sigmoid\")\n",
    "plot_sigmoid_outputs(\n",
    "    train_sig_input=train_sig_inputs,\n",
    "    val_sig_input=val_sig_inputs,\n",
    "    train_sig_output=train_sig_outputs,\n",
    "    val_sig_output=val_sig_outputs,\n",
    "    epoch_c=epoch_c,\n",
    "    save=sig_dir,\n",
    ")\n",
    "\n",
    "\n",
    "# Plot training_accs\n",
    "training_accs_dir = os.path.join(run_dir + \"_training_accs\")\n",
    "plot_training_accs(training_accs, epoch_c=epoch_c, save=training_accs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
