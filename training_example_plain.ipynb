{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec31851a-3b4e-4db0-bdad-e2be13979bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax backend cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".XX\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "from jax.lib import xla_bridge\n",
    "print(\"jax backend {}\".format(xla_bridge.get_backend().platform))\n",
    "\n",
    "from SSN_classes import SSN2DTopoV1_ONOFF_local\n",
    "from training import new_two_stage_training\n",
    "from parameters import grid_pars, filter_pars, stimuli_pars, sig_pars, ssn_pars, conn_pars_m, conn_pars_s, ssn_layer_pars, conv_pars, training_pars, loss_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb98a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate A by using the default find_A function of SSN2DTopoV1_ONOFF_local when A is undefined\n",
    "ssn_mid = SSN2DTopoV1_ONOFF_local(\n",
    "    ssn_pars=ssn_pars, # got c_E and c_I as new parameters\n",
    "    grid_pars=grid_pars,\n",
    "    conn_pars=conn_pars_m,\n",
    "    filter_pars=filter_pars,\n",
    "    J_2x2 = ssn_layer_pars.J_2x2_m,\n",
    "    gE = ssn_layer_pars.gE_m, \n",
    "    gI = ssn_layer_pars.gE_s\n",
    ")\n",
    "\n",
    "ssn_pars.A = ssn_mid.A\n",
    "if ssn_pars.phases == 4:\n",
    "    ssn_pars.A2 = ssn_mid.A2\n",
    "\n",
    "####################### TRAINING PARAMETERS #############################\n",
    "constant_ssn_pars = dict(\n",
    "    ssn_pars=ssn_pars,\n",
    "    grid_pars=grid_pars,\n",
    "    conn_pars_m=conn_pars_m,\n",
    "    conn_pars_s=conn_pars_s,\n",
    "    gE=ssn_layer_pars.gE,\n",
    "    gI=ssn_layer_pars.gI,\n",
    "    filter_pars=filter_pars,\n",
    "    conv_pars=conv_pars,# this got a lot of new stuff in it that might be a problem\n",
    "    loss_pars=loss_pars,\n",
    "    noise_type=\"poisson\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import jax.numpy as np\\nimport numpy\\nfrom jax import random\\n\\nimport model\\nimport training_supp\\nfrom util import take_log\\n\\nlogJ_2x2_s = take_log(ssn_layer_pars.J_2x2_s)\\nlogs_2x2 = np.log(ssn_layer_pars.s_2x2_s)\\nlogJ_2x2_m = take_log(ssn_layer_pars.J_2x2_m)\\nlogJ_2x2 = [logJ_2x2_m, logJ_2x2_s]\\nlog_sigma_oris = np.log(ssn_layer_pars.sigma_oris)\\nssn_layer_pars_dict = dict(logJ_2x2=logJ_2x2, kappa_pre=ssn_layer_pars.kappa_pre, kappa_post=ssn_layer_pars.kappa_post) # from two_new_stage...\\nlogJ_2x2 = ssn_layer_pars_dict[\\'logJ_2x2\\']\\nkappa_pre = ssn_layer_pars_dict[\\'kappa_pre\\']\\nkappa_post = ssn_layer_pars_dict[\\'kappa_post\\']\\n    \\nconstant_ssn_pars[\"logs_2x2\"] = logs_2x2\\nconstant_ssn_pars[\"train_ori\"] = stimuli_pars.ref_ori\\nconstant_ssn_pars[\"log_sigma_oris\"] = log_sigma_oris\\nconstant_ssn_pars[\"f_E\"] = ssn_layer_pars.f_E\\nconstant_ssn_pars[\"f_I\"] = ssn_layer_pars.f_I\\nconstant_ssn_pars[\"c_E\"] = ssn_layer_pars.c_E\\nconstant_ssn_pars[\"c_I\"] = ssn_layer_pars.c_I\\n\\nc_E = constant_ssn_pars[\\'c_E\\']\\nc_I = constant_ssn_pars[\\'c_I\\']\\nf_E = constant_ssn_pars[\\'f_E\\']\\nf_I = constant_ssn_pars[\\'f_I\\']\\nlog_sigma_oris = constant_ssn_pars[\\'log_sigma_oris\\']\\n\\nw_sig = sig_pars.w_sig\\nb_sig = sig_pars.b_sig\\nconstant_ssn_pars[\"ssn_mid_ori_map\"] = ssn_mid.ori_map\\nssn_mid_ori_map = constant_ssn_pars[\\'ssn_mid_ori_map\\']\\n\\nlogs_2x2 = constant_ssn_pars[\\'logs_2x2\\']\\nssn_pars = constant_ssn_pars[\\'ssn_pars\\']\\ngrid_pars = constant_ssn_pars[\\'grid_pars\\']\\nconn_pars_m = constant_ssn_pars[\\'conn_pars_m\\']\\nconn_pars_s =constant_ssn_pars[\\'conn_pars_s\\']\\ngE_m =constant_ssn_pars[\\'gE\\'][0]\\ngE_s =constant_ssn_pars[\\'gE\\'][1]\\ngI_m = constant_ssn_pars[\\'gI\\'][0]\\ngI_s = constant_ssn_pars[\\'gI\\'][1]\\nfilter_pars = constant_ssn_pars[\\'filter_pars\\']\\nconv_pars = constant_ssn_pars[\\'conv_pars\\']\\nloss_pars = constant_ssn_pars[\\'loss_pars\\']\\n\\nconstant_ssn_pars[\"key\"] = random.PRNGKey(numpy.random.randint(0, 10000))\\nconstant_ssn_pars = training_supp.generate_noise(constant_ssn_pars, training_pars.sig_noise, training_pars.batch_size, length=w_sig.shape[0], noise_type=\"poisson\")\\nnoise_ref = constant_ssn_pars[\\'noise_ref\\']\\nnoise_target = constant_ssn_pars[\\'noise_target\\']\\nnoise_type = constant_ssn_pars[\\'noise_type\\']\\ntrain_ori = constant_ssn_pars[\\'train_ori\\']\\ndata = training_supp.create_data(stimuli_pars, n_trials=training_pars.batch_size)\\n\\nmodel.two_layer_model(logJ_2x2=logJ_2x2, logs_2x2=logs_2x2, c_E=c_E, c_I=c_I, f_E=f_E, f_I=f_I, w_sig=w_sig, b_sig=b_sig, sigma_oris=log_sigma_oris, kappa_pre=kappa_pre, kappa_post=kappa_post, ssn_mid_ori_map=ssn_mid_ori_map, ssn_sup_ori_map=ssn_mid_ori_map, train_data=data, ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars_m=conn_pars_m, conn_pars_s=conn_pars_s, gE_m=gE_m, gI_m=gI_m, gE_s=gE_s, gI_s=gI_s, filter_pars=filter_pars, conv_pars=conv_pars, loss_pars=loss_pars, noise_ref=noise_ref, noise_target=noise_target)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import jax.numpy as np\n",
    "import numpy\n",
    "from jax import random\n",
    "\n",
    "import model\n",
    "import training_supp\n",
    "from util import take_log\n",
    "\n",
    "logJ_2x2_s = take_log(ssn_layer_pars.J_2x2_s)\n",
    "logs_2x2 = np.log(ssn_layer_pars.s_2x2_s)\n",
    "logJ_2x2_m = take_log(ssn_layer_pars.J_2x2_m)\n",
    "logJ_2x2 = [logJ_2x2_m, logJ_2x2_s]\n",
    "log_sigma_oris = np.log(ssn_layer_pars.sigma_oris)\n",
    "ssn_layer_pars_dict = dict(logJ_2x2=logJ_2x2, kappa_pre=ssn_layer_pars.kappa_pre, kappa_post=ssn_layer_pars.kappa_post) # from two_new_stage...\n",
    "logJ_2x2 = ssn_layer_pars_dict['logJ_2x2']\n",
    "kappa_pre = ssn_layer_pars_dict['kappa_pre']\n",
    "kappa_post = ssn_layer_pars_dict['kappa_post']\n",
    "    \n",
    "constant_ssn_pars[\"logs_2x2\"] = logs_2x2\n",
    "constant_ssn_pars[\"train_ori\"] = stimuli_pars.ref_ori\n",
    "constant_ssn_pars[\"log_sigma_oris\"] = log_sigma_oris\n",
    "constant_ssn_pars[\"f_E\"] = ssn_layer_pars.f_E\n",
    "constant_ssn_pars[\"f_I\"] = ssn_layer_pars.f_I\n",
    "constant_ssn_pars[\"c_E\"] = ssn_layer_pars.c_E\n",
    "constant_ssn_pars[\"c_I\"] = ssn_layer_pars.c_I\n",
    "\n",
    "c_E = constant_ssn_pars['c_E']\n",
    "c_I = constant_ssn_pars['c_I']\n",
    "f_E = constant_ssn_pars['f_E']\n",
    "f_I = constant_ssn_pars['f_I']\n",
    "log_sigma_oris = constant_ssn_pars['log_sigma_oris']\n",
    "\n",
    "w_sig = sig_pars.w_sig\n",
    "b_sig = sig_pars.b_sig\n",
    "constant_ssn_pars[\"ssn_mid_ori_map\"] = ssn_mid.ori_map\n",
    "ssn_mid_ori_map = constant_ssn_pars['ssn_mid_ori_map']\n",
    "\n",
    "logs_2x2 = constant_ssn_pars['logs_2x2']\n",
    "ssn_pars = constant_ssn_pars['ssn_pars']\n",
    "grid_pars = constant_ssn_pars['grid_pars']\n",
    "conn_pars_m = constant_ssn_pars['conn_pars_m']\n",
    "conn_pars_s =constant_ssn_pars['conn_pars_s']\n",
    "gE_m =constant_ssn_pars['gE'][0]\n",
    "gE_s =constant_ssn_pars['gE'][1]\n",
    "gI_m = constant_ssn_pars['gI'][0]\n",
    "gI_s = constant_ssn_pars['gI'][1]\n",
    "filter_pars = constant_ssn_pars['filter_pars']\n",
    "conv_pars = constant_ssn_pars['conv_pars']\n",
    "loss_pars = constant_ssn_pars['loss_pars']\n",
    "\n",
    "constant_ssn_pars[\"key\"] = random.PRNGKey(numpy.random.randint(0, 10000))\n",
    "constant_ssn_pars = training_supp.generate_noise(constant_ssn_pars, training_pars.sig_noise, training_pars.batch_size, length=w_sig.shape[0], noise_type=\"poisson\")\n",
    "noise_ref = constant_ssn_pars['noise_ref']\n",
    "noise_target = constant_ssn_pars['noise_target']\n",
    "noise_type = constant_ssn_pars['noise_type']\n",
    "train_ori = constant_ssn_pars['train_ori']\n",
    "data = training_supp.create_data(stimuli_pars, n_trials=training_pars.batch_size)\n",
    "\n",
    "model.two_layer_model(logJ_2x2=logJ_2x2, logs_2x2=logs_2x2, c_E=c_E, c_I=c_I, f_E=f_E, f_I=f_I, w_sig=w_sig, b_sig=b_sig, sigma_oris=log_sigma_oris, kappa_pre=kappa_pre, kappa_post=kappa_post, ssn_mid_ori_map=ssn_mid_ori_map, ssn_sup_ori_map=ssn_mid_ori_map, train_data=data, ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars_m=conn_pars_m, conn_pars_s=conn_pars_s, gE_m=gE_m, gI_m=gI_m, gE_s=gE_s, gI_s=gI_s, filter_pars=filter_pars, conv_pars=conv_pars, loss_pars=loss_pars, noise_ref=noise_ref, noise_target=noise_target)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading orientation map\n",
      "#### NOT SAVING! ####\n",
      "Training loss: 3.4372832775115967 ¦ Validation -- loss: 3.872570753097534, true accuracy: 0.4699999988079071, at epoch 0, (time 21.341131448745728, 0.40685033798217773), \n",
      "Training accuracy: 0.5600000023841858, all losses[[1.6296686 ]\n",
      " [0.40785038]\n",
      " [0.57385534]\n",
      " [0.825909  ]\n",
      " [0.        ]\n",
      " [3.4372833 ]]\n",
      "Training loss: 3.699962615966797 ¦ Validation -- loss: 3.279947519302368, true accuracy: 0.5799999833106995, at epoch 1, (time 18.330333471298218, 0.5619125366210938), \n",
      "Training loss: 2.2161335945129395 ¦ Validation -- loss: 2.1909475326538086, true accuracy: 0.7599999904632568, at epoch 20, (time 1.68170166015625, 0.4160428047180176), \n",
      "Entering second stage at epoch 20\n",
      "Training loss: 2.1901259422302246 ¦ Validation -- loss: 2.1988868713378906, true accuracy: 0.75, at epoch 1, (time 1.68170166015625, 1.8430020809173584)\n",
      "Training accuracy: 0.7400000095367432, all losses[[8.4341758e-01]\n",
      " [4.0583763e-01]\n",
      " [5.7432824e-01]\n",
      " [3.6639914e-01]\n",
      " [1.4342861e-04]\n",
      " [2.1901259e+00]]\n",
      "Training loss: 1.351481556892395 ¦ Validation -- loss: 1.57550048828125, true accuracy: 0.6000000238418579, at epoch 20, (time 1.68170166015625, 1.7868328094482422)\n",
      "[[ 1.8184032 -1.0711308]\n",
      " [ 3.8643079 -1.6026962]]\n",
      "[[ 1.935     -1.0062   ]\n",
      " [ 3.6377997 -1.7028   ]]\n",
      "[[ 4.209157  -1.756687 ]\n",
      " [ 5.2826357 -1.3183166]]\n",
      "[[ 4.4413204 -1.6582118]\n",
      " [ 5.0289063 -1.2416493]]\n"
     ]
    }
   ],
   "source": [
    "########### TRAINING ############\n",
    "([ssn_layer_pars_dict, readout_pars],\n",
    "    val_loss_per_epoch,\n",
    "    training_losses,\n",
    "    training_accs,\n",
    "    train_sig_inputs,\n",
    "    train_sig_outputs,\n",
    "    val_sig_inputs,\n",
    "    val_sig_outputs,\n",
    "    epoch_c,\n",
    "    save_w_sigs) = new_two_stage_training(\n",
    "    ssn_layer_pars,\n",
    "    sig_pars,\n",
    "    training_pars,\n",
    "    constant_ssn_pars,\n",
    "    stimuli_pars,\n",
    "    extra_stop=2,\n",
    "    ssn_ori_map=ssn_mid.ori_map\n",
    ")\n",
    "\n",
    "from training_supp import sep_exponentiate\n",
    "print(sep_exponentiate(ssn_layer_pars_dict['logJ_2x2'][0]))\n",
    "print(ssn_layer_pars.J_2x2_m)\n",
    "print(sep_exponentiate(ssn_layer_pars_dict['logJ_2x2'][1]))\n",
    "print(ssn_layer_pars.J_2x2_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[ 4  5 24  6  0]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import numpy as np\n",
    "\n",
    "vv = lambda x, y: jnp.vdot(x, y)  #  ([a], [a]) -> []\n",
    "mv = jax.vmap(vv, (0, None), 0) \n",
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([1,0,1])\n",
    "print(vv(v1,v2))\n",
    "m1 = np.array([[1,0,1],[2, 0, 1], [4, 4, 4], [1, 1, 1], [0, 0, 0]])\n",
    "print(mv(m1,v1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
