{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec31851a-3b4e-4db0-bdad-e2be13979bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax backend cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".XX\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "from jax.lib import xla_bridge\n",
    "print(\"jax backend {}\".format(xla_bridge.get_backend().platform))\n",
    "\n",
    "from SSN_classes import SSN_mid_local\n",
    "from training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb98a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully to: results/Nov23_v0\n",
      "Files copied successfully to: results/Nov23_v1\n",
      "Training model for 5 epochs  with learning rate 0.001, sig_noise 2.0 at offset 4.0, lam_w 1, batch size 50, noise_type poisson\n",
      "Saving results to csv  results/Nov23_v1\\results.csv\n",
      "Training loss: 1.338036060333252 ¦ Validation -- loss: 1.5556433200836182, true accuracy: 0.4399999976158142, at epoch 1, (time 50.96613907814026, 0.8963532447814941), \n",
      "Training loss: 1.6727712154388428 ¦ Validation -- loss: 1.5336360931396484, true accuracy: 0.5199999809265137, at epoch 3, (time 2.397770404815674, 1.1182911396026611), \n",
      "Training loss: 1.7069448232650757 ¦ Validation -- loss: 1.5380905866622925, true accuracy: 0.5, at epoch 5, (time 2.1164016723632812, 1.0537660121917725), \n",
      "Entering second stage at epoch 5\n",
      "Training loss: 1.3961068391799927 ¦ Validation -- loss: 1.3785502910614014, true accuracy: 0.5199999809265137, at epoch 1, (time 2.1164016723632812, 2.701303720474243)\n",
      "Training accuracy: 0.5400000214576721, all losses[[9.7601163e-01]\n",
      " [9.3572348e-02]\n",
      " [2.7227223e-01]\n",
      " [5.4239787e-02]\n",
      " [1.0774854e-05]\n",
      " [1.3961068e+00]]\n",
      "Training loss: 1.33286714553833 ¦ Validation -- loss: 1.2567222118377686, true accuracy: 0.5400000214576721, at epoch 3, (time 2.1164016723632812, 2.78894305229187)\n",
      "Training loss: 1.4438210725784302 ¦ Validation -- loss: 1.3879257440567017, true accuracy: 0.47999998927116394, at epoch 5, (time 2.1164016723632812, 2.6418838500976562)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n([ssn_layer_pars_dict, readout_pars],\\n    val_loss_per_epoch,\\n    training_losses,\\n    training_accs,\\n    train_sig_inputs,\\n    train_sig_outputs,\\n    val_sig_inputs,\\n    val_sig_outputs,\\n    epoch_c,\\n    save_w_sigs) = new_two_stage_training(\\n    ssn_layer_pars,\\n    sig_pars,\\n    training_pars,\\n    constant_ssn_pars,\\n    stimuli_pars,\\n    extra_stop=2,\\n    ssn_ori_map=ssn_ori_map_loaded\\n    )\\n    '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as np\n",
    "\n",
    "from parameters import grid_pars, filter_pars, stimuli_pars, sig_pars, ssn_pars, conn_pars_m, conn_pars_s, ssn_layer_pars, conv_pars, training_pars, loss_pars\n",
    "\n",
    "# check where A2 is defined in Clara's code\n",
    "ssn_ori_map_loaded = np.load(os.path.join(os.getcwd(), 'ssn_map_uniform_good.npy'))\n",
    "#Find normalization constant of Gabor filters\n",
    "ssn_mid=SSN_mid_local(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars_m, filter_pars=filter_pars, J_2x2= ssn_layer_pars.J_2x2_m, gE = ssn_layer_pars.gE_m, gI=ssn_layer_pars.gI_m, ori_map = ssn_ori_map_loaded)\n",
    "ssn_pars.A = ssn_mid.A\n",
    "ssn_pars.A2 = ssn_mid.A2\n",
    "####################### TRAINING PARAMETERS #############################\n",
    "constant_ssn_pars = dict(\n",
    "    ssn_pars=ssn_pars,\n",
    "    grid_pars=grid_pars,\n",
    "    conn_pars_m=conn_pars_m,\n",
    "    conn_pars_s=conn_pars_s,\n",
    "    gE=ssn_layer_pars.gE,\n",
    "    gI=ssn_layer_pars.gI,\n",
    "    filter_pars=filter_pars,\n",
    "    conv_pars=conv_pars,# this got a lot of new stuff in it that might be a problem\n",
    "    loss_pars=loss_pars,\n",
    "    noise_type=\"poisson\",\n",
    ")\n",
    "#Collect constant parameters into single class\n",
    "class constant_pars:\n",
    "    ssn_pars = ssn_pars\n",
    "    s_2x2 = ssn_layer_pars.s_2x2_s\n",
    "    sigma_oris = ssn_layer_pars.sigma_oris\n",
    "    grid_pars = grid_pars\n",
    "    conn_pars_m = conn_pars_m\n",
    "    conn_pars_s = conn_pars_s\n",
    "    gE = ssn_layer_pars.gE\n",
    "    gI = ssn_layer_pars.gI\n",
    "    filter_pars = filter_pars\n",
    "    noise_type = 'poisson'\n",
    "    ssn_ori_map = ssn_ori_map_loaded\n",
    "    ref_ori = stimuli_pars.ref_ori\n",
    "    \n",
    "readout_pars = dict(w_sig = sig_pars.w_sig, b_sig = sig_pars.b_sig)\n",
    "ssn_layer_pars = dict(J_2x2_m = ssn_layer_pars.J_2x2_m, J_2x2_s = ssn_layer_pars.J_2x2_s, c_E = ssn_layer_pars.c_E, c_I = ssn_layer_pars.c_I, f_E = ssn_layer_pars.f_E, f_I = ssn_layer_pars.f_I, kappa_pre = ssn_layer_pars.kappa_pre, kappa_post = ssn_layer_pars.kappa_post)\n",
    "\n",
    "########### TRAINING ############\n",
    "from save_code import save_code\n",
    "results_dir = save_code()\n",
    "file_name = 'results.csv'\n",
    "results_filename = os.path.join(results_dir,file_name)\n",
    "(\n",
    "        [ssn_layer_pars, readout_pars],\n",
    "        val_loss_per_epoch,\n",
    "        all_losses,\n",
    "        train_accs,\n",
    "        train_sig_input,\n",
    "        train_sig_output,\n",
    "        val_sig_input,\n",
    "        val_sig_output,\n",
    "        epochs_plot,\n",
    "        save_w_sigs,\n",
    "    ) = train_model(\n",
    "    ssn_layer_pars,\n",
    "    readout_pars,\n",
    "    constant_pars,\n",
    "    conv_pars,\n",
    "    loss_pars,\n",
    "    training_pars,\n",
    "    stimuli_pars,\n",
    "    results_filename\n",
    ")\n",
    "\n",
    "'''\n",
    "([ssn_layer_pars_dict, readout_pars],\n",
    "    val_loss_per_epoch,\n",
    "    training_losses,\n",
    "    training_accs,\n",
    "    train_sig_inputs,\n",
    "    train_sig_outputs,\n",
    "    val_sig_inputs,\n",
    "    val_sig_outputs,\n",
    "    epoch_c,\n",
    "    save_w_sigs) = new_two_stage_training(\n",
    "    ssn_layer_pars,\n",
    "    sig_pars,\n",
    "    training_pars,\n",
    "    constant_ssn_pars,\n",
    "    stimuli_pars,\n",
    "    extra_stop=2,\n",
    "    ssn_ori_map=ssn_ori_map_loaded\n",
    "    )\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6551722  0.01111201]\n",
      " [1.2963108  0.5273492 ]]\n"
     ]
    }
   ],
   "source": [
    "print(ssn_layer_pars['J_2x2_m'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
